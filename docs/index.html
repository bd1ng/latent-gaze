<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Latent Gaze</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

    <!--Title Section--> 
    <section class="title">
        <div class="masked-layer">
            <div class="rotating-bg"></div>
            <h1 class="masked-title">The Latent Gaze</h1>
        </div>
        <div class="corner-text">
            <p>Bochu Ding, Duke Culture I/O Lab & Explainable AI</p>
        </div>
    </section>

    <!-- Opener -->
    <section class="open">
        <div class="open-line">
            <p>
                What does it look like to be a 
                <span class="blank-line">
                    <span id="open-wordDisplay"></span>
                </span> ?
            </p>
        </div>
        <div class = "intro-trigger"></div>
      </section>

    <!-- Github Link -->
    <section>
        <div class="icons">
            <a href="https://github.com/bd1ng/model-gaze" target="_blank">
                <img src="assets/github.svg" class="icon" alt="GitHub">
            </a>
        </div>    
    </section>
    
    <!-- Intro Photo -->
    <section class="intro-section">
        <div class="intro-photo">
            <img src="photos/intro-photo.png" alt="Main Photo">
        </div>
        <div class="grid-container"></div>  
        <div class="final-photo">
            <img src="photos/immigrant_med.png" />
        </div>
        <div class="pixel-trigger" style="height: 100vh;"></div>
          
    </section>

    <!-- ZoomDots -->
    <section class="zoom-pin-section">
        <div class="zoom-dot-overlay">
            <div class="zoom-dot" style="left: 19.875%; top: 24.625%; background-color: rgb(125, 126, 117);"></div>
            <div class="zoom-dot" style="left: 48.5%; top: 46.25%; background-color: rgb(162, 87, 53);"></div>
            <div class="zoom-dot" style="left: 75.375%; top: 75.875%; background-color: rgb(39, 33, 30);"></div>
          </div>
    </section>
    
    <!-- Final Grid -->
    <section class="final-grid-wrapper">
        <div class="final-photo-container">
          <img class="final-photo" src="photos/final-grid/immigrant_med.png" />
        </div>
      
        <div class="final-grid" id="finalGrid">
          <!-- First cell will be .final-photo; others created dynamically -->
        </div>
    </section>
      
    <!-- Zoom Modal -->
      <div class="modal" id="zoomModal" onclick="closeModal()">
        <div class="modal-inner">
          <img id="zoomImg" />
          <p id="zoomCaption"></p>
        </div>
      </div>
    
    <!-- Scroll Lines  -->
    <section>
        <div class="scroll-line">
        <p class="scroll-text">This isn't a real person.</p>
        </div>
        <div class="scroll-line">
            <p class="scroll-text">It was generated by Stable Diffusion's XL model, a powerful text-to-image generator optimized for creating photorealistic faces.</p>
        </div>
        <div class="scroll-line">
            <p class="scroll-text">This project explores what models are trained to "see" — what characteristics, generalizations, and biases are embedded in them.</p>
        </div>
        <div class="scroll-line">
            <p class="scroll-text">By prompting the model with single-word social designations, I explore how they interpret identity through visual representation. </p>
        </div>
        <div class="scroll-line">
            <p class="scroll-text">These are all portraits of the prompt "an immigrant."</p>
        </div>
        <div class="scroll-line">
            <p class="scroll-text">For each label, I generated thousands of portraits.</p>
        </div>
        <div class="scroll-line">
            <p class="scroll-text">Merged together, they become a composite — a portrait of the label itself.</p>
        </div>
        <div class="scroll-line">
            <p class="scroll-text">In each composite, each pixel represents the median value of that pixel across all generated images.</p>
        </div>
        <div class="scroll-line">
            <p class="scroll-text">I invite you to explore these faces — a reflection of the data they were born from.</p>
        </div>
        <div class="scroll-line" style="opacity: 0;">
            <p class="scroll-text">Section 10.</p>
        </div>
        <div class="scroll-line" style="opacity: 0;">
            <p class="scroll-text">Section 11.</p>
        </div>
        <div class="scroll-line" style="opacity: 0;">
            <p class="scroll-text">Section 12.</p>
        </div>
        <div class="scroll-line" style="opacity: 0;">
            <p class="scroll-text">Look at you, peeking into the html!</p>
        </div>
        <div id="scroll-end-marker" style="height: 10px; visibility: hidden;"></div>
    </section>

    <!-- Final Page -->
    <section class="final-page" id="finalPage">
        <div class="final-left">
          <h1>Fin.</h1>
        </div>
        <div class="final-right">
            <h2>In Closing</h2>
            <p>These portraits illuminate the assumptions generative AI models can make. But many, if not, most AI/ML systems don’t have easily perceptible outputs. Yet they accelerate decision-making in every domain, from financial services to healthcare, in ways that profoundly shape our lives. Their biases are less visible, but their impacts are consequential. This project begins with what we can see — and invites us to look closer, especially when it seems like we can't.  </p>

            <h2>References:</h2>
            <p>“ThisPersonDoesNotExist: Images of a White World Culture” — Kris Belden-Adams, University of Mississippi</p>
            <p>“Easily Accessible Text-to-Image Generation Amplifies Demographic Stereotypes at Large Scale” — Bianchi et al. 
            <a href="https://dl.acm.org/doi/abs/10.1145/3593013.3594095" target="_blank">[link]</a></p>
            <p>“How AI reduces the world to stereotypes” — Victoria Turk, Rest of the World 
            <a href="https://restofworld.org/2023/ai-image-stereotypes/" target="_blank">[link]</a></p>
            <p>“Google’s ‘Woke’ Image Generator Shows the Limitations of AI” — David Gilbert, Wired 
            <a href="https://www.wired.com/story/google-gemini-woke-ai-image-generation/" target="_blank">[link]</a></p>
            <p>“I Asked A.I. Where It Thought I Was From. Its Answer: Nowhere.” — Nouf Aljowaysir, New York Times 
            <a href="https://www.nytimes.com/2024/06/04/opinion/artificial-intelligence-oral-storytelling.html" target="_blank">[link]</a></p>
            <p>ComfyUI Workflow Reference — Andrés Zsögön 
            <a href="https://www.andreszsogon.com/comfyui-load-prompts-from-text-file-sample-workflow/" target="_blank">[link]</a></p>
      
            <h2>Special Thanks</h2>
            <p><em>With special thanks to Professors Augustus Wendell, Brinnae Bent, and Vivek Rao.</em></p>
        </div>
    </section>
          
    <!-- Scripts -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.12.2/gsap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.12.2/ScrollTrigger.min.js"></script>
    <script src="script.js"></script>

    <!-- Zoom Dot Overlay -->
    <div class="zoom-dot-overlay"></div>
</body>
</html>
